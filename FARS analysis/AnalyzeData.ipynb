{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and modules\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database2014.txt ...\n",
      "Number of rows in dataset: 72888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# load the dataset\n",
    "list_ = []\n",
    "for file_ in ['Database2014.txt']:\n",
    "    #,'Database2013.txt']:#,'Database2012.txt','Database2011.txt',]:\n",
    "    print('Loading', file_, '...')\n",
    "    try:\n",
    "        #df = pd.read_csv(file_,index_col=None, header=0)\n",
    "        df = pd.read_csv(file_, engine = 'python', sep='\\t', index_col='Obs.')\n",
    "    except OSError:\n",
    "        print('!!file not found!!')\n",
    "        break\n",
    "    list_.append(df)\n",
    "data = pd.concat(list_)\n",
    "\n",
    "for key in data.keys():\n",
    "    if key.startswith('Unnamed'):\n",
    "        data = data.drop(key, 1)\n",
    "print('Number of rows in dataset:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select interesting stuff\n",
    "# --------------\n",
    "\n",
    "# Load Code manual\n",
    "import pickle\n",
    "code_manual = pickle.load( open( \"CodeManual.p\", \"rb\" ) )\n",
    "\n",
    "# Select interesting features and map them to their respective\n",
    "#   names in the code manual\n",
    "translate_column_names = {\n",
    "'driverdrowsy' : 'Drowsy driver',\n",
    "'ptype' : 'Person Type',\n",
    "'druginv' : 'Police Reported Drug Involvement',\n",
    "'heavytruck': 'Large Truck Related',\n",
    "'schlbus' : 'School Bus Related',\n",
    "'sex' : 'Sex',\n",
    "'race' : 'Race',\n",
    "'reljuncinter' : 'Relation To Junction: Within Interchange Area',\n",
    "'atmcond': 'Atmospheric Condition (1)',\n",
    "'holiday' : 'Holiday Related',\n",
    "'nhs' : 'National Highway System',\n",
    "'hispanic' : 'Hispanic',\n",
    "'rfun' : 'Roadway Function Class',\n",
    "'lightcond' : 'Light Condition',\n",
    "'speeding' : 'Speeding',\n",
    "'dayofweek' : 'Day Of Week',\n",
    "}\n",
    "\n",
    "also_interesting = ['age', 'alcres']\n",
    "\n",
    "labelsOfInter = list(translate_column_names.keys())\n",
    "labelsOfInter.extend(also_interesting)\n",
    "for item in['heavytruck','schlbus','reljuncinter']:\n",
    "    labelsOfInter.remove(item)\n",
    "\n",
    "\n",
    "data = data[labelsOfInter].applymap(lambda x: -1 if x == '.' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhs',\n",
       " 'holiday',\n",
       " 'speeding',\n",
       " 'race',\n",
       " 'rfun',\n",
       " 'sex',\n",
       " 'dayofweek',\n",
       " 'atmcond',\n",
       " 'hispanic',\n",
       " 'druginv',\n",
       " 'driverdrowsy',\n",
       " 'ptype',\n",
       " 'lightcond',\n",
       " 'age',\n",
       " 'alcres']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsOfInter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dimensionality\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collapse some features values\n",
    "# ------------\n",
    "\n",
    "# Categorize on number of Fatalities\n",
    "def NumFatalitiesToCategory(num):\n",
    "    if num <3:\n",
    "        return 1\n",
    "    elif (num>=3) and (num<6):\n",
    "        return 2\n",
    "    return 3\n",
    "\n",
    "# Reduce categories in 'Light Condition'\n",
    "code_manual[translate_column_names['lightcond']][11] = 'Dawn/Dusk'\n",
    "code_manual[translate_column_names['lightcond']][12] = 'Dark'\n",
    "def Collaps_lightcond(num):\n",
    "    if num == 4 or num == 5:\n",
    "        return 11\n",
    "    elif num in [6,8,9]: #unknown\n",
    "        return -1\n",
    "    return num\n",
    "\n",
    "# Reduce categories in \"Roadway Function Class\"\n",
    "code_manual[translate_column_names['rfun']][21] = 'Rural'\n",
    "code_manual[translate_column_names['rfun']][22] = 'Urban'\n",
    "def Collaps_rfun(num):\n",
    "    if num in range(1,10):\n",
    "        return 21\n",
    "    elif num in range(11,20):\n",
    "        return 22\n",
    "    elif num == 99: #unknown\n",
    "        return -1\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Holiday Related\"\n",
    "code_manual[translate_column_names['holiday']][-1] = 'Not Holiday or Unknow date'\n",
    "code_manual[translate_column_names['holiday']][1] = 'Was Holiday'\n",
    "def Collaps_holiday(num):\n",
    "    if num >0:\n",
    "        return 1\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Atmospheric Condition (1)\"\n",
    "code_manual[translate_column_names['atmcond']][1] = 'Clear or Cloudy'\n",
    "code_manual[translate_column_names['atmcond']][2] = 'Precipitation'\n",
    "code_manual[translate_column_names['atmcond']][4] = 'Snow'\n",
    "code_manual[translate_column_names['atmcond']][6] = \"Severe \\\n",
    "Crosswinds, Blowing Sand, Soil, Dirt\",\n",
    "def Collaps_atmcond(num):\n",
    "    if num in [8, 0, 98, 99]: #other or not known\n",
    "        return -1\n",
    "    elif num in [1,10]:\n",
    "        return 1\n",
    "    elif num in [2,12,3]:\n",
    "        return 2\n",
    "    elif num in [6,7]:\n",
    "        return 6\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Person Type\"\n",
    "code_manual[translate_column_names['ptype']][1] = 'In a Motor vehicle'\n",
    "code_manual[translate_column_names['ptype']][4] = 'Non-Motor vehicle'\n",
    "def Collaps_ptype(num):\n",
    "    if num in [-1,19]: #other or not known\n",
    "        return -1\n",
    "    elif num in [1,2,9,3]:\n",
    "        return 1\n",
    "    elif num in [4,8,6,7]:\n",
    "        return 4\n",
    "    return num\n",
    "\n",
    "# Reduce categories in \"Hispanic\"\n",
    "code_manual[translate_column_names['hispanic']][10] = 'Is Hispanic'\n",
    "def Collaps_hispanic(num):\n",
    "    if num in [-1,99,0]: #other or not known\n",
    "        return -1\n",
    "    elif num in range(1,7):\n",
    "        return 10\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Race\"\n",
    "code_manual[translate_column_names['race']][30] = 'American Indian or Hawaiian'\n",
    "code_manual[translate_column_names['race']][31] = 'Asian (not Indian)'\n",
    "code_manual[translate_column_names['race']][32] = 'Indian'\n",
    "def Collaps_race(num):\n",
    "    if num in [-1, 0, 98, 99, 97]: #other or not known\n",
    "        return -1\n",
    "    elif num in [3,6]:  \n",
    "        return 30\n",
    "    elif num in [4,5,7,28,38,48,58,68,78]:  \n",
    "        return 31\n",
    "    elif num in [18,19]:  \n",
    "        return 32\n",
    "    return num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply reduction of categories cardinality\n",
    "data.lightcond = data.lightcond.apply(Collaps_lightcond )\n",
    "data.rfun      = data.rfun.apply(Collaps_rfun  )\n",
    "data.holiday   = data.holiday.apply(Collaps_holiday )\n",
    "data.atmcond   = data.atmcond.apply(Collaps_atmcond )\n",
    "data.ptype     = data.ptype.apply(Collaps_ptype )\n",
    "data.hispanic  = data.hispanic.apply(Collaps_hispanic )\n",
    "data.race      = data.race.apply(Collaps_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map different types of 'unknown' to a single number\n",
    "unknown = {'druginv': [8,9],\n",
    "           'nhs'    : [9],\n",
    "           'reljuncinter': [8,9],\n",
    "           'dayofweek': [-1,9],\n",
    "           'sex'     : [8,9],\n",
    "           'age'     : [-1, 998, 999],\n",
    "           'alcres'  : [95, 96, 97, 98, 99],\n",
    "           'druginv' : [-1, 8, 9]\n",
    "          }\n",
    "\n",
    "# collaps all keys for 'unknown' into '-1' value\n",
    "for feature in unknown.keys():\n",
    "    try:\n",
    "        data[feature] = data[feature].apply(lambda x: \n",
    "                                            x if x not in unknown[feature] \n",
    "                                            else -1)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot encoder where needed\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_a_label(dataset, labl_to_categ = 'drug'):\n",
    "    '''\n",
    "    Use One-hot encoder on a categorical feature,\n",
    "    join it back to the original dataframe\n",
    "    and return the new dataframe\n",
    "    '''\n",
    "    tt = dataset[labl_to_categ]\n",
    "    tt_df = pd.get_dummies(tt)\n",
    "    tt_df.columns = [ '%s:%d'%(labl_to_categ, value) for value in tt_df.keys() ]\n",
    "    dataset = dataset.join(tt_df)\n",
    "    dataset = dataset.drop(labl_to_categ,1)\n",
    "    return dataset\n",
    "\n",
    "categorical_features_list = ['lightcond', 'schlbus', 'druginv', 'nhs', \n",
    "                             'speeding', 'rfun', 'holiday',\n",
    "                           'atmcond', 'heavytruck', 'reljuncinter', \n",
    "                             'ptype', 'dayofweek',\n",
    "                           'hispanic', 'race', 'driverdrowsy']\n",
    "non_categ_features_list = [ 'sex', 'age', 'alcres' ]\n",
    "\n",
    "target_name = 'dayofweek'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in data.keys():\n",
    "    if feature == target_name:\n",
    "        continue\n",
    "    elif feature in categorical_features_list:\n",
    "        data = categorize_a_label(data, labl_to_categ = feature)\n",
    "    elif feature in non_categ_features_list:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"!!! Don't know whether\", feature, 'is categorical or not')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select n features, analyze and return score\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_for_classifier = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_analysis(clean_dataset, target_name, returnClassifier=False):\n",
    "    # Separate into train_features, train_label and test_feature, test_label\n",
    "    threshold = int(round(len(clean_dataset)*.70))\n",
    "    train_features  = clean_dataset[:threshold].drop(target_name,1)\n",
    "    test_feature    = clean_dataset[threshold:].drop(target_name,1)\n",
    "    train_label     = clean_dataset[target_name][:threshold]\n",
    "    test_label      = clean_dataset[target_name][threshold:]\n",
    "    \n",
    "    # Train decision tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(max_depth = max_depth_for_classifier)\n",
    "    clf.fit(train_features, train_label)\n",
    "    predict = clf.predict(test_feature)\n",
    "     \n",
    "    if returnClassifier:\n",
    "        return clf.score(test_feature, test_label), clf\n",
    "    return clf.score(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations as comb\n",
    "output = {}\n",
    "target_name = 'dayofweek'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- nhs\n",
      "holiday, speeding, race, rfun, sex, atmcond, hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- holiday\n",
      "speeding, race, rfun, sex, atmcond, hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- speeding\n",
      "race, rfun, sex, atmcond, hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- race\n",
      "rfun, sex, atmcond, hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- rfun\n",
      "sex, atmcond, hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- sex\n",
      "atmcond, hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- atmcond\n",
      "hispanic, druginv, driverdrowsy, ptype, lightcond, \n",
      "-- hispanic\n",
      "druginv, driverdrowsy, ptype, lightcond, \n",
      "-- druginv\n",
      "driverdrowsy, ptype, lightcond, \n",
      "-- driverdrowsy\n",
      "ptype, lightcond, \n",
      "-- ptype\n"
     ]
    }
   ],
   "source": [
    "ww0 = ''\n",
    "ww = ''\n",
    "for sel_feat in comb(labelsOfInter, 4):\n",
    "    features = list(sel_feat)\n",
    "   \n",
    "    if target_name in features:\n",
    "        features = features.remove(target_name)\n",
    "        continue\n",
    "    if str(features) in output.keys():\n",
    "        continue\n",
    "        \n",
    "    #is it a new word?\n",
    "    if features[0] != ww:\n",
    "        print('\\n--', features[0])\n",
    "        ww = features[0]\n",
    "    try:\n",
    "        if features[1] != ww0:\n",
    "            print(features[1], end=\", \")\n",
    "            ww0 = features[1]      \n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    # There are many keys in the dataset for one feature\n",
    "    # because we passed the one-hot encoder.\n",
    "    #  we want to select all keys corresponding to\n",
    "    #  the given feature\n",
    "    sel_keys = []\n",
    "    for feat in features:\n",
    "        for key in data.keys():\n",
    "            if key.startswith(feat):\n",
    "                sel_keys.append(key)\n",
    "    sel_keys.append(target_name)\n",
    "    clean = data[sel_keys]#.copy()\n",
    "\n",
    "    output[str(features)] = run_analysis(clean, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>score</th>\n",
       "      <th>rel_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['nhs', 'race', 'druginv', 'alcres']</td>\n",
       "      <td>0.194869</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['nhs', 'rfun', 'ptype', 'alcres']</td>\n",
       "      <td>0.194869</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['rfun', 'driverdrowsy', 'ptype', 'alcres']</td>\n",
       "      <td>0.194823</td>\n",
       "      <td>0.999765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['holiday', 'rfun', 'ptype', 'alcres']</td>\n",
       "      <td>0.194732</td>\n",
       "      <td>0.999296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['race', 'hispanic', 'druginv', 'alcres']</td>\n",
       "      <td>0.194640</td>\n",
       "      <td>0.998827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['rfun', 'sex', 'hispanic', 'alcres']</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.997184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['holiday', 'driverdrowsy', 'ptype', 'alcres']</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.997184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['holiday', 'rfun', 'hispanic', 'alcres']</td>\n",
       "      <td>0.194228</td>\n",
       "      <td>0.996714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['rfun', 'hispanic', 'driverdrowsy', 'alcres']</td>\n",
       "      <td>0.194228</td>\n",
       "      <td>0.996714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['race', 'ptype', 'age', 'alcres']</td>\n",
       "      <td>0.194183</td>\n",
       "      <td>0.996480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feat     score  rel_score\n",
       "0            ['nhs', 'race', 'druginv', 'alcres']  0.194869   1.000000\n",
       "1              ['nhs', 'rfun', 'ptype', 'alcres']  0.194869   1.000000\n",
       "2     ['rfun', 'driverdrowsy', 'ptype', 'alcres']  0.194823   0.999765\n",
       "3          ['holiday', 'rfun', 'ptype', 'alcres']  0.194732   0.999296\n",
       "4       ['race', 'hispanic', 'druginv', 'alcres']  0.194640   0.998827\n",
       "5           ['rfun', 'sex', 'hispanic', 'alcres']  0.194320   0.997184\n",
       "6  ['holiday', 'driverdrowsy', 'ptype', 'alcres']  0.194320   0.997184\n",
       "7       ['holiday', 'rfun', 'hispanic', 'alcres']  0.194228   0.996714\n",
       "8  ['rfun', 'hispanic', 'driverdrowsy', 'alcres']  0.194228   0.996714\n",
       "9              ['race', 'ptype', 'age', 'alcres']  0.194183   0.996480"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = pd.Series(output)\n",
    "pp =pp.sort_values(ascending=False)[:10]\n",
    "\n",
    "#plot the top 10\n",
    "pl = pp.to_frame('score')\n",
    "pl = pl.reset_index()\n",
    "pl.columns = ['feat', 'score']\n",
    "pl['rel_score'] = pl.score.apply(lambda x: x/max(pl.score)) \n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot top results\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.charts.attributes import CatAttr\n",
    "from bokeh.plotting import show, output_file\n",
    "#output_notebook()\n",
    "output_file(\"barchart.html\", title=\"results\")\n",
    "\n",
    "#TOOLS = \"pan,wheel_zoom,box_zoom,reset,resize,save\"\n",
    "#fig = figure(tools=TOOLS, toolbar_location=\"left\", logo=\"grey\", plot_width=120)\n",
    "\n",
    "\n",
    "p = Bar(pl, label=CatAttr(columns=['feat'], sort=False),\n",
    "        values='rel_score', \n",
    "        title=\"Scores per set of features\",\n",
    "        color=\"blue\",\n",
    "        ylabel=\"score (relative to max score)\",\n",
    "        xlabel='',\n",
    "        plot_width = 900)\n",
    "p.y_range = Range1d(round(pl.rel_score.iloc[-1],3),pl.rel_score.iloc[1])\n",
    "show(p)\n",
    "\n",
    "\n",
    "#Bar(pl).io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the tree\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rules(clf, features, labels, node_index=0, simple_leaf_string=True):\n",
    "    \"\"\"Structure of rules in a fit decision tree classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : DecisionTreeClassifier\n",
    "        A tree that has already been fit.\n",
    "\n",
    "    features, labels : lists of str\n",
    "        The names of the features and labels, respectively.\n",
    "\n",
    "    \"\"\"\n",
    "    node = {}\n",
    "    if clf.tree_.children_left[node_index] == -1:  # indicates leaf\n",
    "        count_labels = zip(clf.tree_.value[node_index, 0], labels)\n",
    "        node['name'] = ', '.join(('{} of {}'.format(int(count), label)\n",
    "                                  for count, label in count_labels))\n",
    "        if simple_leaf_string:\n",
    "            node['name'] = simplify_string(node['name'])\n",
    "    else:\n",
    "        feature = features[clf.tree_.feature[node_index]]\n",
    "        threshold = clf.tree_.threshold[node_index]\n",
    "        node['name'] = '{} > {}'.format(feature, threshold)\n",
    "        left_index = clf.tree_.children_left[node_index]\n",
    "        right_index = clf.tree_.children_right[node_index]\n",
    "        node['children'] = [rules(clf, features, labels, right_index, simple_leaf_string),\n",
    "                            rules(clf, features, labels, left_index, simple_leaf_string)]\n",
    "    return node\n",
    "\n",
    "def simplify_string(st):\n",
    "    #st = '772 of Sun, 838 of Mon, 862 of Tue, 899 of Wed, 919 of Thu, 1024 of Fri, 994 of Sat'\n",
    "    st = st.split(', ')\n",
    "    nums = [ int(entry.split()[0]) for entry in st ]\n",
    "    pred_day = label_dictionary[nums.index(max(nums))]\n",
    "    return pred_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the tree for the winning set of features\n",
    "#-------------\n",
    "\n",
    "# retrieve winning set of features\n",
    "ss = pl.feat.iloc[0]\n",
    "for char in ['[', ']', \"'\"]:\n",
    "    ss = ss.replace(char, '')\n",
    "ff = ss.split(',')\n",
    "\n",
    "sel_keys = []\n",
    "for feat in ff:\n",
    "    feat = feat.strip()\n",
    "    for key in data.keys():\n",
    "        if key.startswith(feat):\n",
    "            sel_keys.append(key)\n",
    "sel_keys.append(target_name)\n",
    "\n",
    "# re-do analysis and catch classifier\n",
    "clean = data[sel_keys]\n",
    "num_, classfr = run_analysis(clean, target_name, returnClassifier=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhs:-1',\n",
       " 'nhs:0',\n",
       " 'nhs:1',\n",
       " 'race:-1',\n",
       " 'race:1',\n",
       " 'race:2',\n",
       " 'race:30',\n",
       " 'race:31',\n",
       " 'race:32',\n",
       " 'druginv:-1',\n",
       " 'druginv:0',\n",
       " 'druginv:1',\n",
       " 'alcres']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if target_name in sel_keys:\n",
    "    sel_keys.remove(target_name)\n",
    "\n",
    "sel_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "label_dictionary = 'Sun Mon Tue Wed Thu Fri Sat'.split()\n",
    "\n",
    "r = rules(classfr, sel_keys, label_dictionary, simple_leaf_string=True)\n",
    "with open('rules_maxdepth%d.json'%(max_depth_for_classifier), 'w') as f:\n",
    "    f.write(json.dumps(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
